import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, recall_score, f1_score, precision_score
from xgboost import XGBClassifier
import joblib
import os

# ğŸ“¥ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("data/processed/cleaned_binary.csv")

# ğŸ¯ íŠ¹ì„± ë° ë¼ë²¨
features = [
    'tcp.flags', 'tcp.time_delta',
    'mqtt.kalive', 'mqtt.qos', 'mqtt.retain', 'mqtt.len',
    'mqtt.dupflag', 'mqtt.msgtype'
]
X = df[features]
y = df['binary_label']

# ğŸ§ª train/test ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ğŸ”„ ì •ê·œí™”
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# âš–ï¸ class imbalance ë¹„ìœ¨ ê³„ì‚°
normal_count = sum(y_train == 0)
attack_count = sum(y_train == 1)
scale_pos_weight = normal_count / attack_count

# ğŸš€ ëª¨ë¸ í•™ìŠµ
model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=scale_pos_weight,
    eval_metric='logloss',
    random_state=42
)
model.fit(X_train_scaled, y_train)

# ğŸ¯ ì˜ˆì¸¡ í™•ë¥ ë¡œë¶€í„° threshold ì ìš©
y_probs = model.predict_proba(X_test_scaled)[:, 1]

# ğŸ”¥ threshold ì„¤ì • (0.6 ~ 0.7 ì •ë„ë¡œ ì‹¤í—˜ ê°€ëŠ¥)
threshold = 0.70
y_pred = (y_probs >= threshold).astype(int)

# ğŸ“Š í‰ê°€
print(f"âœ… Threshold = {threshold}")
print("ğŸ“Š ì •ìƒ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n", classification_report(y_test, y_pred))
print("\n\n\tì •ìƒ\n\tê³µê²©")

recall = recall_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"ğŸ¯ Recall(ê³µê²©): {recall:.4f}")
print(f"ğŸ¯ Precision(ê³µê²©): {precision:.4f}")
print(f"ğŸ¯ F1-score(ê³µê²©): {f1:.4f}")

# ğŸ’¾ ëª¨ë¸ ì €ì¥
os.makedirs("models", exist_ok=True)
joblib.dump(model, "models/xgb_binary_model.pkl")
joblib.dump(scaler, "models/xgb_binary_scaler.pkl")
print("âœ… ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ")