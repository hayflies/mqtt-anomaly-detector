import pandas as pd
import numpy as np
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix
from config import TRAIN_PATH, TEST_PATH, MODEL_PATH
import warnings
warnings.filterwarnings('ignore')

# ğŸ”¹ í´ë˜ìŠ¤ ì •ì˜
class_names = [ 'legitimate', 'dos', 'flood', 'bruteforce', 'malformed', 'slowite']
target_mapping = {name: idx for idx, name in enumerate(class_names)}
inverse_mapping = {idx: name for name, idx in target_mapping.items()}

# ğŸ”¹ ë°ì´í„° ë¡œë”©
df_train = pd.read_csv(TRAIN_PATH, low_memory=False)
df_test = pd.read_csv(TEST_PATH, low_memory=False)

# ğŸ”¹ íƒ€ê²Ÿ ì¸ì½”ë”©
df_train['target'] = df_train['target'].map(target_mapping)
df_test['target'] = df_test['target'].map(target_mapping)

# ğŸ”¹ í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
X_train = df_train.drop('target', axis=1)
y_train = df_train['target']
X_test = df_test.drop('target', axis=1)
y_test = df_test['target']

# ğŸ”¹ ë¬¸ìì—´ â†’ ì½”ë“œí™”
for col in X_train.columns:
    if X_train[col].dtype == 'object':
        X_train[col] = X_train[col].astype('category').cat.codes
        X_test[col] = X_test[col].astype('category').cat.codes

# ğŸ”¹ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ â†’ ìƒ˜í”Œ ê°€ì¤‘ì¹˜ ì ìš©
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)
weights = np.array([class_weights[label] for label in y_train])

# ğŸ”¹ DMatrix ìƒì„±
dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights)
dvalid = xgb.DMatrix(X_test, label=y_test)

alpha_dict = {
    0: 0.25,  # legitimate (ì¤„ì„)
    1: 0.25,  # dos (ì¤„ì„)
    2: 0.5,  # flood
    3: 0.5,  # bruteforce
    4: 0.5,  # malformed
    5: 0.25  # slowite (ì¤„ì„)
}

# ğŸ”¹ Focal Loss ì •ì˜
def focal_loss(alpha_dict, gamma=2.0, num_classes=6):
    def focal_obj(preds, dtrain):
        labels = dtrain.get_label().astype(int)
        preds = preds.reshape(-1, num_classes)
        preds = np.clip(preds, -10, 10)
        exp_preds = np.exp(preds - np.max(preds, axis=1, keepdims=True))
        probs = exp_preds / np.sum(exp_preds, axis=1, keepdims=True)
        one_hot = np.eye(num_classes)[labels]
        pt = (probs * one_hot).sum(axis=1).reshape(-1, 1)
        alpha_vec = np.array([alpha_dict[label] for label in labels]).reshape(-1, 1)
        grad = -alpha_vec * (1 - pt) ** gamma * (one_hot - probs)
        hess = alpha_vec * (1 - pt) ** gamma * (1 - probs) * probs * (gamma + 1)
        return grad.reshape(-1), hess.reshape(-1)
    return focal_obj

# ğŸ”¹ XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„°
params = {
    'objective': 'multi:softprob',
    'num_class': len(class_names),
    'eval_metric': 'mlogloss',
    'eta': 0.05,
    'max_depth': 6,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'gamma': 0.1,
    'lambda': 1,
    'alpha': 0.1,
    'seed': 42
}

# ğŸ”¹ í•™ìŠµ

print("ğŸš€ XGBoost + Focal Loss í•™ìŠµ ì‹œì‘...")
evals = [(dtrain, 'train'), (dvalid, 'eval')]
model = xgb.train(
    params,
    dtrain,
    num_boost_round=1000,
    obj=focal_loss(alpha_dict, gamma=2.0, num_classes=len(class_names)),
    evals=evals,
    early_stopping_rounds=50,
    verbose_eval=100
)

# ğŸ”¹ ëª¨ë¸ ì €ì¥
model.save_model(MODEL_PATH)
print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {MODEL_PATH}")

# ğŸ”¹ ì˜ˆì¸¡
print("ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ì¤‘...")
y_pred = model.predict(dvalid)
y_pred_classes = np.argmax(y_pred, axis=1)

# ğŸ”¹ ë¶„ë¥˜ ë¦¬í¬íŠ¸ ì¶œë ¥
print("âœ… ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
report_dict = classification_report(
    y_test, y_pred_classes,
    target_names=class_names,
    output_dict=True
)
report_df = pd.DataFrame(report_dict).transpose()
print(report_df)

# ğŸ”¹ ì‹œê°í™” - ì„±ëŠ¥ ì§€í‘œ
report_df = report_df.iloc[:-3, :]
report_df[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(10, 6))
plt.title("Per-Class Precision, Recall, F1 Score")
plt.ylabel("Score")
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

# ğŸ”¹ í˜¼ë™ í–‰ë ¬
cm = confusion_matrix(y_test, y_pred_classes, normalize='true')
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Reds', fmt='.2f', xticklabels=class_names, yticklabels=class_names)
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()
